<h1>Метод k-ближайших соседей</h1>

<p>
  kNN расшифровывается как k Nearest Neighbor или k Ближайших Соседей — это один из самых простых алгоритмов классификации, также иногда используемый в задачах       
  регрессии. Благодаря своей простоте, он является хорошим примером, с которого можно начать знакомство с областью Machine Learning. 
</p>

<p>
  Задача классификации в машинном обучении — это задача отнесения объекта к одному из заранее определенных классов на основании его формализованных признаков. 
  Каждый из объектов в этой задаче представляется в виде вектора в N-мерном пространстве, каждое измерение в котором представляет собой описание одного из признаков 
  объекта. 
</p>

<p>
  Рассмотрим задачу kNN при k = 1 на языке R, используя датасет "Ирисы Фишера". Для начала выберем тренировочную выборку по ширине и длине лепестка и виду ириса. В нашей выборке 150 ирисов. 
</p>
![screenshot of sample]()


Создадим набор из 15 тестовых точек с ограничениями по длине и ширине лепестка. 
Отбразим тренировочную выборку. Рисуя тестовые точки, запускаем алгоритм 1NN для определения принадлежности одному из трёх существующих классов. 
В самой функции 1NN ищем ближайшего по Евклидову расстоянию соседа для текущей точки и возвращаем вид ириса для неё же. 

